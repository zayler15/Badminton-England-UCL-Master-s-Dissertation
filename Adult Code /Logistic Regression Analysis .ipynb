{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "#from fancyimpute import IterativeImputer\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_imputed = pd.read_csv('df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency_Racket          float64\n",
      "Duration_Racket           float64\n",
      "Mins_Badminton_Perweek    float64\n",
      "Badminton_Duration        float64\n",
      "Badminton_12_Momths       float64\n",
      "Time                        int64\n",
      "IMD                       float64\n",
      "Serial                     string\n",
      "LA                         object\n",
      "Age                       float64\n",
      "Child                      object\n",
      "Diability                  object\n",
      "Education                  object\n",
      "Ethnicity                  object\n",
      "Gender                     object\n",
      "Workstatus                 object\n",
      "BMI                        object\n",
      "Badminton_Frequency        object\n",
      "Plays_badminton           float64\n",
      "Plays_racket              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_imputed.dtypes\n",
    "\n",
    "# List of continuous columns\n",
    "continuous_cols = ['Frequency_Racket', 'Duration_Racket','Mins_Badminton_Perweek',\n",
    "                   'Badminton_Duration','Badminton_12_Momths','Age','Time','IMD']\n",
    "\n",
    "# Convert variables not in continuous_cols to object data type\n",
    "for col in df_imputed.columns:\n",
    "    if col not in continuous_cols:\n",
    "        df_imputed[col] = df_imputed[col].astype('object')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert variables to numeric data type\n",
    "df_imputed['Plays_badminton'] = pd.to_numeric(df_imputed['Plays_badminton'], errors='coerce')\n",
    "df_imputed['Plays_racket'] = pd.to_numeric(df_imputed['Plays_racket'], errors='coerce')\n",
    "df_imputed['Serial'] = df_imputed['Serial'].astype(\"string\")\n",
    "\n",
    "\n",
    "# Check the data types\n",
    "print(df_imputed.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency_Racket</th>\n",
       "      <th>Duration_Racket</th>\n",
       "      <th>Mins_Badminton_Perweek</th>\n",
       "      <th>Badminton_Duration</th>\n",
       "      <th>Badminton_12_Momths</th>\n",
       "      <th>Time</th>\n",
       "      <th>IMD</th>\n",
       "      <th>Serial</th>\n",
       "      <th>LA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Child</th>\n",
       "      <th>Diability</th>\n",
       "      <th>Education</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Workstatus</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Badminton_Frequency</th>\n",
       "      <th>Plays_badminton</th>\n",
       "      <th>Plays_racket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>160480126774181.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>151160011004881.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>151160011005981.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>151160011007481.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>151160011007482.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>211090336822241.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211090336822991.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117752</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211090336823721.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117753</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211090336823722.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117754</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>211090336824061.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117755 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency_Racket  Duration_Racket  Mins_Badminton_Perweek  \\\n",
       "0                     0.0              0.0                     0.0   \n",
       "1                     0.0              0.0                     0.0   \n",
       "2                     0.0              0.0                     0.0   \n",
       "3                     0.0              0.0                     0.0   \n",
       "4                     0.0              0.0                     0.0   \n",
       "...                   ...              ...                     ...   \n",
       "1117750               0.0              0.0                     0.0   \n",
       "1117751               0.0              0.0                     0.0   \n",
       "1117752               0.0              0.0                     0.0   \n",
       "1117753               0.0              0.0                     0.0   \n",
       "1117754               0.0              0.0                     0.0   \n",
       "\n",
       "         Badminton_Duration  Badminton_12_Momths  Time   IMD  \\\n",
       "0                       0.0                  0.0     1  10.0   \n",
       "1                       0.0                  0.0     1   6.0   \n",
       "2                       0.0                  0.0     1  10.0   \n",
       "3                       0.0                  0.0     1   9.0   \n",
       "4                       0.0                  0.0     1   9.0   \n",
       "...                     ...                  ...   ...   ...   \n",
       "1117750                 0.0                  0.0     6   6.0   \n",
       "1117751                 0.0                  0.0     6   9.0   \n",
       "1117752                 0.0                  0.0     6   5.0   \n",
       "1117753                 0.0                  0.0     6   5.0   \n",
       "1117754                 0.0                  0.0     6   2.0   \n",
       "\n",
       "                    Serial     LA  Age Child Diability Education Ethnicity  \\\n",
       "0        160480126774181.0  155.0  8.0   1.0       2.0       1.0       7.0   \n",
       "1        151160011004881.0  123.0  6.0   1.0       2.0       1.0       1.0   \n",
       "2        151160011005981.0  123.0  4.0   3.0       2.0       3.0       1.0   \n",
       "3        151160011007481.0  123.0  7.0   1.0       2.0       3.0       1.0   \n",
       "4        151160011007482.0  123.0  7.0   1.0       2.0       3.0       1.0   \n",
       "...                    ...    ...  ...   ...       ...       ...       ...   \n",
       "1117750  211090336822241.0  174.0  2.0   1.0       1.0       2.0       1.0   \n",
       "1117751  211090336822991.0   78.0  5.0   1.0       2.0       1.0       2.0   \n",
       "1117752  211090336823721.0   78.0  6.0   1.0       2.0       3.0       1.0   \n",
       "1117753  211090336823722.0   78.0  6.0   1.0       2.0       2.0       1.0   \n",
       "1117754  211090336824061.0   78.0  3.0   1.0       2.0       5.0       7.0   \n",
       "\n",
       "        Gender Workstatus  BMI Badminton_Frequency  Plays_badminton  \\\n",
       "0          2.0        5.0  2.0                 0.0              0.0   \n",
       "1          1.0        1.0  3.0                 0.0              0.0   \n",
       "2          2.0        6.0  2.0                 0.0              0.0   \n",
       "3          1.0        1.0  2.0                 0.0              0.0   \n",
       "4          1.0        1.0  2.0                 0.0              0.0   \n",
       "...        ...        ...  ...                 ...              ...   \n",
       "1117750    2.0        8.0  2.0                 0.0              0.0   \n",
       "1117751    1.0        1.0  2.0                 0.0              0.0   \n",
       "1117752    1.0        1.0  3.0                 0.0              0.0   \n",
       "1117753    2.0        2.0  2.0                 0.0              0.0   \n",
       "1117754    1.0        2.0  2.0                 0.0              0.0   \n",
       "\n",
       "         Plays_racket  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "1117750           0.0  \n",
       "1117751           0.0  \n",
       "1117752           0.0  \n",
       "1117753           0.0  \n",
       "1117754           0.0  \n",
       "\n",
       "[1117755 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836/2767508293.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  X = pd.get_dummies(df_imputed[[ 'Child','Diability','Education',\n"
     ]
    }
   ],
   "source": [
    "#Encoding the data \n",
    "X = pd.get_dummies(df_imputed[[ 'Child','Diability','Education', \n",
    "                               'Ethnicity', 'Gender', 'Workstatus', 'BMI']],drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "X[\"Time\"] = df_imputed['Time']\n",
    "X[\"IMD\"] = df_imputed['IMD']\n",
    "X['Age'] = df_imputed['Age']\n",
    "#Standardising the data \n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child_2.0</th>\n",
       "      <th>Child_3.0</th>\n",
       "      <th>Child_4.0</th>\n",
       "      <th>Diability_2.0</th>\n",
       "      <th>Education_2.0</th>\n",
       "      <th>Education_3.0</th>\n",
       "      <th>Education_4.0</th>\n",
       "      <th>Education_5.0</th>\n",
       "      <th>Education_6.0</th>\n",
       "      <th>Ethnicity_2.0</th>\n",
       "      <th>Ethnicity_3.0</th>\n",
       "      <th>Ethnicity_4.0</th>\n",
       "      <th>Ethnicity_5.0</th>\n",
       "      <th>Ethnicity_6.0</th>\n",
       "      <th>Ethnicity_7.0</th>\n",
       "      <th>Gender_2.0</th>\n",
       "      <th>Gender_3.0</th>\n",
       "      <th>Workstatus_2.0</th>\n",
       "      <th>Workstatus_3.0</th>\n",
       "      <th>Workstatus_4.0</th>\n",
       "      <th>Workstatus_5.0</th>\n",
       "      <th>Workstatus_6.0</th>\n",
       "      <th>Workstatus_7.0</th>\n",
       "      <th>Workstatus_8.0</th>\n",
       "      <th>Workstatus_9.0</th>\n",
       "      <th>Workstatus_10.0</th>\n",
       "      <th>BMI_2.0</th>\n",
       "      <th>BMI_3.0</th>\n",
       "      <th>BMI_4.0</th>\n",
       "      <th>BMI_5.0</th>\n",
       "      <th>Time</th>\n",
       "      <th>IMD</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>11.434535</td>\n",
       "      <td>0.89269</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>1.583657</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>-1.406496</td>\n",
       "      <td>1.543002</td>\n",
       "      <td>1.522406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-1.068711</td>\n",
       "      <td>1.541757</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>-1.406496</td>\n",
       "      <td>0.146220</td>\n",
       "      <td>0.407251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>2.957257</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>2.288636</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>0.89269</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>5.507812</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>-1.406496</td>\n",
       "      <td>1.543002</td>\n",
       "      <td>-0.707905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>2.288636</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>-1.406496</td>\n",
       "      <td>1.193806</td>\n",
       "      <td>0.964828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>2.288636</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>-1.406496</td>\n",
       "      <td>1.193806</td>\n",
       "      <td>0.964828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117750</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>-2.199386</td>\n",
       "      <td>2.490704</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>0.89269</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>5.326256</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>1.503443</td>\n",
       "      <td>0.146220</td>\n",
       "      <td>-1.823060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117751</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>4.226031</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>1.503443</td>\n",
       "      <td>1.193806</td>\n",
       "      <td>-0.150327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117752</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>2.288636</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.431869</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-1.068711</td>\n",
       "      <td>1.541757</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>1.503443</td>\n",
       "      <td>-0.202976</td>\n",
       "      <td>0.407251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117753</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>2.490704</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>-0.222499</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>-0.087454</td>\n",
       "      <td>0.89269</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>2.315516</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>1.503443</td>\n",
       "      <td>-0.202976</td>\n",
       "      <td>0.407251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117754</th>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>-0.176585</td>\n",
       "      <td>0.454672</td>\n",
       "      <td>-0.401493</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.142971</td>\n",
       "      <td>4.494409</td>\n",
       "      <td>-0.294742</td>\n",
       "      <td>-0.236629</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>-0.122359</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.108405</td>\n",
       "      <td>11.434535</td>\n",
       "      <td>-1.12021</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>2.315516</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.120707</td>\n",
       "      <td>-0.631450</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.187749</td>\n",
       "      <td>-0.051772</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.399065</td>\n",
       "      <td>-0.12427</td>\n",
       "      <td>1.503443</td>\n",
       "      <td>-1.250562</td>\n",
       "      <td>-1.265483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117755 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Child_2.0  Child_3.0  Child_4.0  Diability_2.0  Education_2.0  \\\n",
       "0        -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "1        -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "2        -0.360761   2.957257  -0.176585       0.454672      -0.401493   \n",
       "3        -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "4        -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "...            ...        ...        ...            ...            ...   \n",
       "1117750  -0.360761  -0.338151  -0.176585      -2.199386       2.490704   \n",
       "1117751  -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "1117752  -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "1117753  -0.360761  -0.338151  -0.176585       0.454672       2.490704   \n",
       "1117754  -0.360761  -0.338151  -0.176585       0.454672      -0.401493   \n",
       "\n",
       "         Education_3.0  Education_4.0  Education_5.0  Education_6.0  \\\n",
       "0            -0.436941      -0.142971      -0.222499      -0.294742   \n",
       "1            -0.436941      -0.142971      -0.222499      -0.294742   \n",
       "2             2.288636      -0.142971      -0.222499      -0.294742   \n",
       "3             2.288636      -0.142971      -0.222499      -0.294742   \n",
       "4             2.288636      -0.142971      -0.222499      -0.294742   \n",
       "...                ...            ...            ...            ...   \n",
       "1117750      -0.436941      -0.142971      -0.222499      -0.294742   \n",
       "1117751      -0.436941      -0.142971      -0.222499      -0.294742   \n",
       "1117752       2.288636      -0.142971      -0.222499      -0.294742   \n",
       "1117753      -0.436941      -0.142971      -0.222499      -0.294742   \n",
       "1117754      -0.436941      -0.142971       4.494409      -0.294742   \n",
       "\n",
       "         Ethnicity_2.0  Ethnicity_3.0  Ethnicity_4.0  Ethnicity_5.0  \\\n",
       "0            -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "1            -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "2            -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "3            -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "4            -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "...                ...            ...            ...            ...   \n",
       "1117750      -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "1117751       4.226031      -0.208818      -0.122359      -0.075131   \n",
       "1117752      -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "1117753      -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "1117754      -0.236629      -0.208818      -0.122359      -0.075131   \n",
       "\n",
       "         Ethnicity_6.0  Ethnicity_7.0  Gender_2.0  Gender_3.0  Workstatus_2.0  \\\n",
       "0            -0.108405      11.434535     0.89269   -0.037767       -0.431869   \n",
       "1            -0.108405      -0.087454    -1.12021   -0.037767       -0.431869   \n",
       "2            -0.108405      -0.087454     0.89269   -0.037767       -0.431869   \n",
       "3            -0.108405      -0.087454    -1.12021   -0.037767       -0.431869   \n",
       "4            -0.108405      -0.087454    -1.12021   -0.037767       -0.431869   \n",
       "...                ...            ...         ...         ...             ...   \n",
       "1117750      -0.108405      -0.087454     0.89269   -0.037767       -0.431869   \n",
       "1117751      -0.108405      -0.087454    -1.12021   -0.037767       -0.431869   \n",
       "1117752      -0.108405      -0.087454    -1.12021   -0.037767       -0.431869   \n",
       "1117753      -0.108405      -0.087454     0.89269   -0.037767        2.315516   \n",
       "1117754      -0.108405      11.434535    -1.12021   -0.037767        2.315516   \n",
       "\n",
       "         Workstatus_3.0  Workstatus_4.0  Workstatus_5.0  Workstatus_6.0  \\\n",
       "0             -0.118028       -0.120707        1.583657       -0.181560   \n",
       "1             -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "2             -0.118028       -0.120707       -0.631450        5.507812   \n",
       "3             -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "4             -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "...                 ...             ...             ...             ...   \n",
       "1117750       -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "1117751       -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "1117752       -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "1117753       -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "1117754       -0.118028       -0.120707       -0.631450       -0.181560   \n",
       "\n",
       "         Workstatus_7.0  Workstatus_8.0  Workstatus_9.0  Workstatus_10.0  \\\n",
       "0             -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "1             -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "2             -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "3             -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "4             -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "...                 ...             ...             ...              ...   \n",
       "1117750       -0.158558        5.326256       -0.051772        -0.166945   \n",
       "1117751       -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "1117752       -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "1117753       -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "1117754       -0.158558       -0.187749       -0.051772        -0.166945   \n",
       "\n",
       "          BMI_2.0   BMI_3.0   BMI_4.0  BMI_5.0      Time       IMD       Age  \n",
       "0        0.935707 -0.648611 -0.399065 -0.12427 -1.406496  1.543002  1.522406  \n",
       "1       -1.068711  1.541757 -0.399065 -0.12427 -1.406496  0.146220  0.407251  \n",
       "2        0.935707 -0.648611 -0.399065 -0.12427 -1.406496  1.543002 -0.707905  \n",
       "3        0.935707 -0.648611 -0.399065 -0.12427 -1.406496  1.193806  0.964828  \n",
       "4        0.935707 -0.648611 -0.399065 -0.12427 -1.406496  1.193806  0.964828  \n",
       "...           ...       ...       ...      ...       ...       ...       ...  \n",
       "1117750  0.935707 -0.648611 -0.399065 -0.12427  1.503443  0.146220 -1.823060  \n",
       "1117751  0.935707 -0.648611 -0.399065 -0.12427  1.503443  1.193806 -0.150327  \n",
       "1117752 -1.068711  1.541757 -0.399065 -0.12427  1.503443 -0.202976  0.407251  \n",
       "1117753  0.935707 -0.648611 -0.399065 -0.12427  1.503443 -0.202976  0.407251  \n",
       "1117754  0.935707 -0.648611 -0.399065 -0.12427  1.503443 -1.250562 -1.265483  \n",
       "\n",
       "[1117755 rows x 33 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method bfgs is: gtol, norm, epsilon. The list of unsupported keyword arguments passed include: w. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:              1117755\n",
      "Model:                          Logit   Df Residuals:                  1117721\n",
      "Method:                           MLE   Df Model:                           33\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05452\n",
      "Time:                        06:08:34   Log-Likelihood:            -1.0451e+05\n",
      "converged:                       True   LL-Null:                   -1.1054e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.1592      0.009   -481.574      0.000      -4.176      -4.142\n",
      "Child_2.0           0.0199      0.007      3.067      0.002       0.007       0.033\n",
      "Child_3.0           0.0451      0.006      7.175      0.000       0.033       0.057\n",
      "Child_4.0           0.0047      0.006      0.729      0.466      -0.008       0.017\n",
      "Diability_2.0       0.2700      0.011     24.674      0.000       0.249       0.291\n",
      "Education_2.0      -0.1030      0.007    -14.325      0.000      -0.117      -0.089\n",
      "Education_3.0      -0.0933      0.008    -12.413      0.000      -0.108      -0.079\n",
      "Education_4.0      -0.0675      0.009     -7.674      0.000      -0.085      -0.050\n",
      "Education_5.0      -0.0702      0.009     -8.261      0.000      -0.087      -0.054\n",
      "Education_6.0      -0.1708      0.011    -16.254      0.000      -0.191      -0.150\n",
      "Ethnicity_2.0      -0.0683      0.007     -9.257      0.000      -0.083      -0.054\n",
      "Ethnicity_3.0       0.1353      0.005     27.924      0.000       0.126       0.145\n",
      "Ethnicity_4.0      -0.0584      0.008     -7.006      0.000      -0.075      -0.042\n",
      "Ethnicity_5.0       0.0693      0.004     17.623      0.000       0.062       0.077\n",
      "Ethnicity_6.0       0.0071      0.006      1.192      0.233      -0.005       0.019\n",
      "Ethnicity_7.0      -0.0046      0.007     -0.689      0.491      -0.018       0.008\n",
      "Gender_2.0         -0.1528      0.007    -21.397      0.000      -0.167      -0.139\n",
      "Gender_3.0         -0.0218      0.010     -2.295      0.022      -0.040      -0.003\n",
      "Workstatus_2.0     -0.0238      0.008     -3.110      0.002      -0.039      -0.009\n",
      "Workstatus_3.0     -0.0354      0.007     -4.817      0.000      -0.050      -0.021\n",
      "Workstatus_4.0     -0.0732      0.010     -7.255      0.000      -0.093      -0.053\n",
      "Workstatus_5.0      0.0242      0.011      2.164      0.030       0.002       0.046\n",
      "Workstatus_6.0     -0.0728      0.008     -9.014      0.000      -0.089      -0.057\n",
      "Workstatus_7.0     -0.1335      0.016     -8.552      0.000      -0.164      -0.103\n",
      "Workstatus_8.0      0.0741      0.005     14.373      0.000       0.064       0.084\n",
      "Workstatus_9.0      0.0047      0.006      0.841      0.400      -0.006       0.016\n",
      "Workstatus_10.0    -0.0370      0.008     -4.528      0.000      -0.053      -0.021\n",
      "BMI_2.0            -0.0123      0.023     -0.542      0.588      -0.057       0.032\n",
      "BMI_3.0            -0.0419      0.021     -1.955      0.051      -0.084       0.000\n",
      "BMI_4.0            -0.1216      0.017     -6.972      0.000      -0.156      -0.087\n",
      "BMI_5.0            -0.0789      0.012     -6.475      0.000      -0.103      -0.055\n",
      "Time               -0.3127      0.007    -44.140      0.000      -0.327      -0.299\n",
      "IMD                -0.1700      0.007    -24.399      0.000      -0.184      -0.156\n",
      "Age                -0.3472      0.010    -33.894      0.000      -0.367      -0.327\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "#performing logistic regression to explore the more simple patterns. \n",
    "# Separate the features and target variable\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = X_scaled\n",
    "y = df_imputed['Plays_badminton']\n",
    "\n",
    "# Add constant to the features\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Count the number of samples in each class\n",
    "class_counts = df_imputed['Plays_badminton'].value_counts()\n",
    "\n",
    "# Calculate inverse probability weights\n",
    "weights = class_counts.sum() / (class_counts.shape[0] * class_counts)\n",
    "\n",
    "# Create and fit logistic regression model with inverse probability weights\n",
    "logit = sm.Logit(y, X)\n",
    "result = logit.fit(method='bfgs', maxiter=100, disp=False, w=weights[y])\n",
    "\n",
    "# Print summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "/tmp/ipykernel_836/187197304.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time  Coefficients  Intercept       MSE  R2 score\n",
      "0 -1.406496     -0.000672   0.027173  0.024318  0.011053\n",
      "1 -0.824508     -0.001790   0.025839  0.024222  0.013556\n",
      "2  -0.24252      0.000672   0.022174  0.021318  0.009327\n",
      "3  0.339467      0.000168   0.021478  0.021179  0.006219\n",
      "4  0.921455      0.002445   0.013089  0.013540  0.008014\n",
      "5  1.503443      0.000956   0.008966  0.008286  0.005860\n",
      "6  Combined      0.000087   0.020182  0.019808  0.009971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836/187197304.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#Time Based Regression \n",
    "\n",
    "# replace 'Time', 'X_scaled', and 'Y' with your actual data\n",
    "time_col = X_scaled['Time']\n",
    "feature_col = X_scaled.drop(['Time'], axis=1)\n",
    "target_col = df_imputed['Plays_badminton']\n",
    "\n",
    "# Get the unique times\n",
    "unique_times = time_col.unique()\n",
    "\n",
    "# DataFrame to hold results\n",
    "results = pd.DataFrame(columns=[\"Time\", \"Coefficients\", \"Intercept\", \"MSE\", \"R2 score\"])\n",
    "\n",
    "# Time based regression\n",
    "for time in unique_times:\n",
    "    time_indices = time_col[time_col == time].index\n",
    "\n",
    "    X_time = feature_col.loc[time_indices]\n",
    "    y_time = target_col.loc[time_indices]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_time, y_time, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results = results.append({\n",
    "        \"Time\": time if pd.notnull(time) else \"Combined\",\n",
    "        \"Coefficients\": model.coef_[0],\n",
    "        \"Intercept\": model.intercept_,\n",
    "        \"MSE\": mse,\n",
    "        \"R2 score\": r2}, ignore_index=True)\n",
    "\n",
    "# Combined times regression\n",
    "X = feature_col\n",
    "y = target_col\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results = results.append({\n",
    "    \"Time\": \"Combined\",\n",
    "    \"Coefficients\": model.coef_[0],\n",
    "    \"Intercept\": model.intercept_,\n",
    "    \"MSE\": mse,\n",
    "    \"R2 score\": r2}, ignore_index=True)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time  Child_2.0  Child_3.0  Child_4.0  Diability_2.0  Education_2.0  \\\n",
      "0  1.503443   0.000087     0.0009    -0.0001       0.003069      -0.001984   \n",
      "1  Combined   0.000087     0.0009    -0.0001       0.003069      -0.001984   \n",
      "\n",
      "   Education_3.0  Education_4.0  Education_5.0  Education_6.0  Ethnicity_2.0  \\\n",
      "0      -0.001568      -0.000932       -0.00106      -0.001736      -0.001415   \n",
      "1      -0.001568      -0.000932       -0.00106      -0.001736      -0.001415   \n",
      "\n",
      "   Ethnicity_3.0  Ethnicity_4.0  Ethnicity_5.0  Ethnicity_6.0  Ethnicity_7.0  \\\n",
      "0       0.004203      -0.001003        0.00273       0.000118      -0.000116   \n",
      "1       0.004203      -0.001003        0.00273       0.000118      -0.000116   \n",
      "\n",
      "   Gender_2.0  Gender_3.0  Workstatus_2.0  Workstatus_3.0  Workstatus_4.0  \\\n",
      "0   -0.003054   -0.000689        -0.00066       -0.000822       -0.001173   \n",
      "1   -0.003054   -0.000689        -0.00066       -0.000822       -0.001173   \n",
      "\n",
      "   Workstatus_5.0  Workstatus_6.0  Workstatus_7.0  Workstatus_8.0  \\\n",
      "0        0.000792       -0.001513       -0.001016        0.003113   \n",
      "1        0.000792       -0.001513       -0.001016        0.003113   \n",
      "\n",
      "   Workstatus_9.0  Workstatus_10.0   BMI_2.0   BMI_3.0  BMI_4.0  BMI_5.0  \\\n",
      "0         0.00015        -0.000646 -0.000952 -0.001591 -0.00258 -0.00111   \n",
      "1         0.00015        -0.000646 -0.000952 -0.001591 -0.00258 -0.00111   \n",
      "\n",
      "        IMD       Age  \n",
      "0 -0.003553 -0.007413  \n",
      "1 -0.003553 -0.007413  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836/2932879215.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  coef_df = coef_df.append(pd.Series([time]+list(model.coef_), index=coef_df.columns), ignore_index=True)\n",
      "/tmp/ipykernel_836/2932879215.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  coef_df = coef_df.append(pd.Series(['Combined']+list(model.coef_), index=coef_df.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "feature_names = feature_col.columns\n",
    "\n",
    "# Create a new DataFrame to hold coefficients\n",
    "coef_df = pd.DataFrame(columns=['Time'] + list(feature_names))\n",
    "\n",
    "# Then inside your loop, instead of the results.append do:\n",
    "coef_df = coef_df.append(pd.Series([time]+list(model.coef_), index=coef_df.columns), ignore_index=True)\n",
    "\n",
    "# And for the combined model\n",
    "coef_df = coef_df.append(pd.Series(['Combined']+list(model.coef_), index=coef_df.columns), ignore_index=True)\n",
    "\n",
    "# Print the coefficients\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Based and Time Combined Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With class-Weights Applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n",
      "/tmp/ipykernel_836/691517348.py:58: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_train.columns = X_train.columns.str.replace('.', '_')\n",
      "/tmp/ipykernel_836/691517348.py:59: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_test.columns = X_test.columns.str.replace('.', '_')\n",
      "/tmp/ipykernel_836/691517348.py:76: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(coef_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Child_2.0</th>\n",
       "      <th>Child_3.0</th>\n",
       "      <th>Child_4.0</th>\n",
       "      <th>Diability_2.0</th>\n",
       "      <th>Education_2.0</th>\n",
       "      <th>Education_3.0</th>\n",
       "      <th>Education_4.0</th>\n",
       "      <th>Education_5.0</th>\n",
       "      <th>Education_6.0</th>\n",
       "      <th>Ethnicity_2.0</th>\n",
       "      <th>Ethnicity_3.0</th>\n",
       "      <th>Ethnicity_4.0</th>\n",
       "      <th>Ethnicity_5.0</th>\n",
       "      <th>Ethnicity_6.0</th>\n",
       "      <th>Ethnicity_7.0</th>\n",
       "      <th>Gender_2.0</th>\n",
       "      <th>Gender_3.0</th>\n",
       "      <th>Workstatus_2.0</th>\n",
       "      <th>Workstatus_3.0</th>\n",
       "      <th>Workstatus_4.0</th>\n",
       "      <th>Workstatus_5.0</th>\n",
       "      <th>Workstatus_6.0</th>\n",
       "      <th>Workstatus_7.0</th>\n",
       "      <th>Workstatus_8.0</th>\n",
       "      <th>Workstatus_9.0</th>\n",
       "      <th>Workstatus_10.0</th>\n",
       "      <th>BMI_2.0</th>\n",
       "      <th>BMI_3.0</th>\n",
       "      <th>BMI_4.0</th>\n",
       "      <th>BMI_5.0</th>\n",
       "      <th>IMD</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.406496</td>\n",
       "      <td>-0.281341</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.613569</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.043943</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.275261</td>\n",
       "      <td>-0.064313</td>\n",
       "      <td>-0.079681</td>\n",
       "      <td>-0.057508</td>\n",
       "      <td>-0.058145</td>\n",
       "      <td>-0.209877</td>\n",
       "      <td>-0.094158</td>\n",
       "      <td>0.143013</td>\n",
       "      <td>-0.037660</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>-0.132019</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>-0.093374</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>-0.077997</td>\n",
       "      <td>-0.091958</td>\n",
       "      <td>0.081460</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.025184</td>\n",
       "      <td>0.047491</td>\n",
       "      <td>-0.005305</td>\n",
       "      <td>-0.083453</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>-0.211051</td>\n",
       "      <td>-0.404033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.824508</td>\n",
       "      <td>-0.283943</td>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>-0.026548</td>\n",
       "      <td>-0.016775</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.306814</td>\n",
       "      <td>-0.081721</td>\n",
       "      <td>-0.058063</td>\n",
       "      <td>-0.090467</td>\n",
       "      <td>-0.068240</td>\n",
       "      <td>-0.185542</td>\n",
       "      <td>-0.070107</td>\n",
       "      <td>0.141139</td>\n",
       "      <td>-0.010398</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>-0.127807</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>-0.039563</td>\n",
       "      <td>-0.030953</td>\n",
       "      <td>-0.030541</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>-0.084662</td>\n",
       "      <td>-0.120333</td>\n",
       "      <td>0.043260</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-0.062338</td>\n",
       "      <td>-0.024014</td>\n",
       "      <td>-0.078946</td>\n",
       "      <td>-0.087481</td>\n",
       "      <td>-0.077639</td>\n",
       "      <td>-0.218384</td>\n",
       "      <td>-0.449212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.24252</td>\n",
       "      <td>-0.217636</td>\n",
       "      <td>0.034187</td>\n",
       "      <td>0.686473</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.028008</td>\n",
       "      <td>0.037399</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>0.339772</td>\n",
       "      <td>-0.062816</td>\n",
       "      <td>-0.076680</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>-0.042722</td>\n",
       "      <td>-0.187671</td>\n",
       "      <td>-0.022499</td>\n",
       "      <td>0.133247</td>\n",
       "      <td>-0.057348</td>\n",
       "      <td>0.077682</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>-0.159578</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>-0.014204</td>\n",
       "      <td>-0.032873</td>\n",
       "      <td>-0.060818</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>-0.030267</td>\n",
       "      <td>-0.158206</td>\n",
       "      <td>0.109037</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>-0.019656</td>\n",
       "      <td>-0.069762</td>\n",
       "      <td>-0.063744</td>\n",
       "      <td>-0.178429</td>\n",
       "      <td>-0.157449</td>\n",
       "      <td>-0.176235</td>\n",
       "      <td>-0.220897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.339467</td>\n",
       "      <td>-0.195027</td>\n",
       "      <td>0.032230</td>\n",
       "      <td>0.605563</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.028916</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>-0.083174</td>\n",
       "      <td>-0.148530</td>\n",
       "      <td>-0.075010</td>\n",
       "      <td>-0.086183</td>\n",
       "      <td>-0.195395</td>\n",
       "      <td>-0.055756</td>\n",
       "      <td>0.162009</td>\n",
       "      <td>-0.079742</td>\n",
       "      <td>0.072385</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>-0.163161</td>\n",
       "      <td>-0.020514</td>\n",
       "      <td>-0.028006</td>\n",
       "      <td>-0.004083</td>\n",
       "      <td>-0.078177</td>\n",
       "      <td>0.060449</td>\n",
       "      <td>-0.097960</td>\n",
       "      <td>-0.102253</td>\n",
       "      <td>0.088617</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>-0.012706</td>\n",
       "      <td>0.047224</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>-0.075206</td>\n",
       "      <td>-0.073515</td>\n",
       "      <td>-0.201614</td>\n",
       "      <td>-0.249970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.921455</td>\n",
       "      <td>-0.364020</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.137799</td>\n",
       "      <td>0.162885</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.314920</td>\n",
       "      <td>-0.166016</td>\n",
       "      <td>-0.163961</td>\n",
       "      <td>-0.145830</td>\n",
       "      <td>-0.082443</td>\n",
       "      <td>-0.167981</td>\n",
       "      <td>-0.044604</td>\n",
       "      <td>0.137438</td>\n",
       "      <td>-0.040083</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.011548</td>\n",
       "      <td>-0.003099</td>\n",
       "      <td>-0.084121</td>\n",
       "      <td>-0.059365</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>-0.020311</td>\n",
       "      <td>-0.056565</td>\n",
       "      <td>-0.047751</td>\n",
       "      <td>-0.059903</td>\n",
       "      <td>-0.097840</td>\n",
       "      <td>0.145003</td>\n",
       "      <td>0.038569</td>\n",
       "      <td>-0.006344</td>\n",
       "      <td>-0.147689</td>\n",
       "      <td>-0.175107</td>\n",
       "      <td>-0.157472</td>\n",
       "      <td>-0.189180</td>\n",
       "      <td>-0.229039</td>\n",
       "      <td>-0.268330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.503443</td>\n",
       "      <td>-0.334317</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.081267</td>\n",
       "      <td>0.131756</td>\n",
       "      <td>0.048425</td>\n",
       "      <td>0.217154</td>\n",
       "      <td>-0.072586</td>\n",
       "      <td>-0.116920</td>\n",
       "      <td>-0.047812</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>-0.156006</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>-0.114383</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>0.023512</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>-0.203961</td>\n",
       "      <td>-0.032613</td>\n",
       "      <td>-0.007490</td>\n",
       "      <td>-0.017108</td>\n",
       "      <td>-0.041243</td>\n",
       "      <td>-0.045679</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.164667</td>\n",
       "      <td>0.132360</td>\n",
       "      <td>0.048202</td>\n",
       "      <td>-0.053716</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.205464</td>\n",
       "      <td>-0.037423</td>\n",
       "      <td>0.272444</td>\n",
       "      <td>-0.265678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combined</td>\n",
       "      <td>-0.235301</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.648927</td>\n",
       "      <td>0.063197</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.293337</td>\n",
       "      <td>-0.082065</td>\n",
       "      <td>-0.082839</td>\n",
       "      <td>-0.053011</td>\n",
       "      <td>-0.065702</td>\n",
       "      <td>-0.183925</td>\n",
       "      <td>-0.057441</td>\n",
       "      <td>0.131980</td>\n",
       "      <td>-0.046310</td>\n",
       "      <td>0.069251</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-0.140047</td>\n",
       "      <td>-0.040349</td>\n",
       "      <td>-0.012760</td>\n",
       "      <td>-0.032662</td>\n",
       "      <td>-0.076163</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>-0.067862</td>\n",
       "      <td>-0.129739</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>-0.031410</td>\n",
       "      <td>-0.031399</td>\n",
       "      <td>-0.053176</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>-0.082701</td>\n",
       "      <td>-0.189430</td>\n",
       "      <td>-0.352395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Intercept  Precision    Recall  F1-score  Child_2.0  Child_3.0  \\\n",
       "0 -1.406496  -0.281341   0.041484  0.613569  0.077713   0.005641   0.043943   \n",
       "1 -0.824508  -0.283943   0.040957  0.625621  0.076881  -0.026548  -0.016775   \n",
       "2  -0.24252  -0.217636   0.034187  0.686473  0.065131   0.028008   0.037399   \n",
       "3  0.339467  -0.195027   0.032230  0.605563  0.061202   0.010438   0.028916   \n",
       "4  0.921455  -0.364020   0.024453  0.621951  0.047055   0.137799   0.162885   \n",
       "5  1.503443  -0.334317   0.015116  0.630872  0.029525   0.081267   0.131756   \n",
       "6  Combined  -0.235301   0.033216  0.648927  0.063197   0.020635   0.049534   \n",
       "\n",
       "   Child_4.0  Diability_2.0  Education_2.0  Education_3.0  Education_4.0  \\\n",
       "0   0.005421       0.275261      -0.064313      -0.079681      -0.057508   \n",
       "1  -0.000424       0.306814      -0.081721      -0.058063      -0.090467   \n",
       "2  -0.029355       0.339772      -0.062816      -0.076680      -0.016494   \n",
       "3   0.003089       0.260512      -0.083174      -0.148530      -0.075010   \n",
       "4   0.060167       0.314920      -0.166016      -0.163961      -0.145830   \n",
       "5   0.048425       0.217154      -0.072586      -0.116920      -0.047812   \n",
       "6   0.009409       0.293337      -0.082065      -0.082839      -0.053011   \n",
       "\n",
       "   Education_5.0  Education_6.0  Ethnicity_2.0  Ethnicity_3.0  Ethnicity_4.0  \\\n",
       "0      -0.058145      -0.209877      -0.094158       0.143013      -0.037660   \n",
       "1      -0.068240      -0.185542      -0.070107       0.141139      -0.010398   \n",
       "2      -0.042722      -0.187671      -0.022499       0.133247      -0.057348   \n",
       "3      -0.086183      -0.195395      -0.055756       0.162009      -0.079742   \n",
       "4      -0.082443      -0.167981      -0.044604       0.137438      -0.040083   \n",
       "5      -0.054317      -0.156006       0.034860       0.189231      -0.114383   \n",
       "6      -0.065702      -0.183925      -0.057441       0.131980      -0.046310   \n",
       "\n",
       "   Ethnicity_5.0  Ethnicity_6.0  Ethnicity_7.0  Gender_2.0  Gender_3.0  \\\n",
       "0       0.076995       0.015110       0.009095   -0.132019    0.010610   \n",
       "1       0.071790       0.005680      -0.005415   -0.127807    0.010708   \n",
       "2       0.077682       0.000169       0.002742   -0.159578    0.013358   \n",
       "3       0.072385       0.019313       0.020006   -0.163161   -0.020514   \n",
       "4       0.052830       0.011548      -0.003099   -0.084121   -0.059365   \n",
       "5       0.091857       0.023512      -0.009935   -0.203961   -0.032613   \n",
       "6       0.069251       0.007862       0.001645   -0.140047   -0.040349   \n",
       "\n",
       "   Workstatus_2.0  Workstatus_3.0  Workstatus_4.0  Workstatus_5.0  \\\n",
       "0       -0.009536       -0.018607       -0.093374        0.002975   \n",
       "1       -0.039563       -0.030953       -0.030541        0.057518   \n",
       "2       -0.014204       -0.032873       -0.060818       -0.027412   \n",
       "3       -0.028006       -0.004083       -0.078177        0.060449   \n",
       "4        0.021105       -0.020311       -0.056565       -0.047751   \n",
       "5       -0.007490       -0.017108       -0.041243       -0.045679   \n",
       "6       -0.012760       -0.032662       -0.076163        0.034865   \n",
       "\n",
       "   Workstatus_6.0  Workstatus_7.0  Workstatus_8.0  Workstatus_9.0  \\\n",
       "0       -0.077997       -0.091958        0.081460       -0.008450   \n",
       "1       -0.084662       -0.120333        0.043260        0.003204   \n",
       "2       -0.030267       -0.158206        0.109037        0.011161   \n",
       "3       -0.097960       -0.102253        0.088617        0.008747   \n",
       "4       -0.059903       -0.097840        0.145003        0.038569   \n",
       "5       -0.064472       -0.164667        0.132360        0.048202   \n",
       "6       -0.067862       -0.129739        0.083166        0.011351   \n",
       "\n",
       "   Workstatus_10.0   BMI_2.0   BMI_3.0   BMI_4.0   BMI_5.0       IMD       Age  \n",
       "0        -0.025184  0.047491 -0.005305 -0.083453 -0.035091 -0.211051 -0.404033  \n",
       "1        -0.062338 -0.024014 -0.078946 -0.087481 -0.077639 -0.218384 -0.449212  \n",
       "2        -0.019656 -0.069762 -0.063744 -0.178429 -0.157449 -0.176235 -0.220897  \n",
       "3        -0.012706  0.047224  0.043508 -0.075206 -0.073515 -0.201614 -0.249970  \n",
       "4        -0.006344 -0.147689 -0.175107 -0.157472 -0.189180 -0.229039 -0.268330  \n",
       "5        -0.053716  0.037528 -0.029078 -0.205464 -0.037423  0.272444 -0.265678  \n",
       "6        -0.031410 -0.031399 -0.053176 -0.138719 -0.082701 -0.189430 -0.352395  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)  # Print all columns\n",
    "\n",
    "# replace 'Time', 'X_scaled', and 'Y' with your actual data\n",
    "time_col = X_scaled['Time']\n",
    "feature_col = X_scaled.drop(['Time'], axis=1)\n",
    "target_col = df_imputed['Plays_badminton']\n",
    "\n",
    "# Get the unique times\n",
    "unique_times = time_col.unique()\n",
    "\n",
    "# Define column names for results dataframe\n",
    "column_names = [\"Time\", \"Intercept\", \"Precision\", \"Recall\", \"F1-score\"] + list(feature_col.columns)\n",
    "\n",
    "# DataFrame to hold results\n",
    "results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Time-based regression\n",
    "for time in unique_times:\n",
    "    time_indices = time_col[time_col == time].index\n",
    "\n",
    "    X_time = feature_col.loc[time_indices]\n",
    "    y_time = target_col.loc[time_indices]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_time, y_time, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = len(y_train) / (2 * np.bincount(y_train))\n",
    "\n",
    "    model = LogisticRegression(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Create a dictionary of feature names and coefficients\n",
    "    coef_dict = dict(zip(feature_col.columns, model.coef_.flatten()))\n",
    "    coef_dict.update({\"Time\": time if pd.notnull(time) else \"Combined\", \"Intercept\": model.intercept_[0], \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})\n",
    "\n",
    "    results = results.append(coef_dict, ignore_index=True)\n",
    "\n",
    "# Combined times regression\n",
    "X = feature_col\n",
    "y = target_col\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Replacing periods in column names with an underscore\n",
    "X_train.columns = X_train.columns.str.replace('.', '_')\n",
    "X_test.columns = X_test.columns.str.replace('.', '_')\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = len(y_train) / (2 * np.bincount(y_train))\n",
    "\n",
    "model = LogisticRegression(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Create a dictionary of feature names and coefficients\n",
    "coef_dict = dict(zip(feature_col.columns, model.coef_.flatten()))\n",
    "coef_dict.update({\"Time\": \"Combined\", \"Intercept\": model.intercept_[0], \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})\n",
    "\n",
    "results = results.append(coef_dict, ignore_index=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.117230\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.114214\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.101374\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.099687\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.070074\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.048867\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.094405\n",
      "         Iterations 9\n",
      "\n",
      "Regression Model for -1.4064956221653189:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               201579\n",
      "Model:                          Logit   Df Residuals:                   201547\n",
      "Method:                           MLE   Df Model:                           31\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05609\n",
      "Time:                        06:08:45   Log-Likelihood:                -23631.\n",
      "converged:                       True   LL-Null:                       -25035.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Child_2.0          -0.0051      0.014     -0.380      0.704      -0.032       0.021\n",
      "Child_3.0           0.0414      0.013      3.231      0.001       0.016       0.067\n",
      "Child_4.0           0.0137      0.013      1.068      0.285      -0.011       0.039\n",
      "Diability_2.0       0.2524      0.023     10.749      0.000       0.206       0.298\n",
      "Education_2.0      -0.0883      0.015     -6.080      0.000      -0.117      -0.060\n",
      "Education_3.0      -0.0760      0.015     -5.022      0.000      -0.106      -0.046\n",
      "Education_4.0      -0.0526      0.017     -3.183      0.001      -0.085      -0.020\n",
      "Education_5.0      -0.0596      0.017     -3.503      0.000      -0.093      -0.026\n",
      "Education_6.0      -0.1737      0.022     -8.067      0.000      -0.216      -0.132\n",
      "Ethnicity_2.0      -0.1025      0.017     -6.203      0.000      -0.135      -0.070\n",
      "Ethnicity_3.0       0.1358      0.010     13.446      0.000       0.116       0.156\n",
      "Ethnicity_4.0      -0.0485      0.017     -2.903      0.004      -0.081      -0.016\n",
      "Ethnicity_5.0       0.0728      0.008      8.949      0.000       0.057       0.089\n",
      "Ethnicity_6.0       0.0058      0.013      0.460      0.646      -0.019       0.031\n",
      "Ethnicity_7.0       0.0093      0.013      0.739      0.460      -0.015       0.034\n",
      "Gender_2.0         -0.1496      0.015    -10.203      0.000      -0.178      -0.121\n",
      "Gender_3.0        102.2038      0.468    218.271      0.000     101.286     103.122\n",
      "Workstatus_2.0     -0.0228      0.016     -1.444      0.149      -0.054       0.008\n",
      "Workstatus_3.0     -0.0389      0.015     -2.531      0.011      -0.069      -0.009\n",
      "Workstatus_4.0     -0.0913      0.023     -4.053      0.000      -0.135      -0.047\n",
      "Workstatus_5.0      0.0085      0.023      0.360      0.719      -0.038       0.055\n",
      "Workstatus_6.0     -0.0829      0.016     -5.102      0.000      -0.115      -0.051\n",
      "Workstatus_7.0     -0.1050      0.029     -3.619      0.000      -0.162      -0.048\n",
      "Workstatus_8.0      0.0643      0.010      6.287      0.000       0.044       0.084\n",
      "Workstatus_9.0     -0.0055      0.012     -0.446      0.655      -0.029       0.019\n",
      "Workstatus_10.0    -0.0319      0.017     -1.904      0.057      -0.065       0.001\n",
      "BMI_2.0             0.0535      0.048      1.117      0.264      -0.040       0.147\n",
      "BMI_3.0             0.0119      0.045      0.262      0.793      -0.077       0.101\n",
      "BMI_4.0            -0.0750      0.037     -2.035      0.042      -0.147      -0.003\n",
      "BMI_5.0            -0.0437      0.025     -1.764      0.078      -0.092       0.005\n",
      "IMD                -0.2043      0.015    -14.059      0.000      -0.233      -0.176\n",
      "Age                -0.4304      0.020    -21.295      0.000      -0.470      -0.391\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for -0.8245079369655084:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               199886\n",
      "Model:                          Logit   Df Residuals:                   199854\n",
      "Method:                           MLE   Df Model:                           31\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05596\n",
      "Time:                        06:08:45   Log-Likelihood:                -22830.\n",
      "converged:                       True   LL-Null:                       -24183.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Child_2.0          -0.0402      0.014     -2.849      0.004      -0.068      -0.013\n",
      "Child_3.0          -0.0301      0.014     -2.156      0.031      -0.058      -0.003\n",
      "Child_4.0          -0.0085      0.013     -0.636      0.525      -0.035       0.018\n",
      "Diability_2.0       0.2716      0.024     11.552      0.000       0.225       0.318\n",
      "Education_2.0      -0.1068      0.015     -7.063      0.000      -0.136      -0.077\n",
      "Education_3.0      -0.0712      0.016     -4.562      0.000      -0.102      -0.041\n",
      "Education_4.0      -0.0952      0.020     -4.847      0.000      -0.134      -0.057\n",
      "Education_5.0      -0.0852      0.018     -4.639      0.000      -0.121      -0.049\n",
      "Education_6.0      -0.1529      0.022     -7.079      0.000      -0.195      -0.111\n",
      "Ethnicity_2.0      -0.0901      0.016     -5.567      0.000      -0.122      -0.058\n",
      "Ethnicity_3.0       0.1323      0.010     12.851      0.000       0.112       0.153\n",
      "Ethnicity_4.0      -0.0218      0.015     -1.432      0.152      -0.052       0.008\n",
      "Ethnicity_5.0       0.0611      0.009      7.001      0.000       0.044       0.078\n",
      "Ethnicity_6.0       0.0004      0.012      0.031      0.975      -0.024       0.025\n",
      "Ethnicity_7.0      -0.0134      0.015     -0.889      0.374      -0.043       0.016\n",
      "Gender_2.0         -0.1402      0.015     -9.452      0.000      -0.169      -0.111\n",
      "Gender_3.0        103.3898      0.482    214.564      0.000     102.445     104.334\n",
      "Workstatus_2.0     -0.0476      0.017     -2.871      0.004      -0.080      -0.015\n",
      "Workstatus_3.0     -0.0359      0.016     -2.262      0.024      -0.067      -0.005\n",
      "Workstatus_4.0     -0.0551      0.020     -2.782      0.005      -0.094      -0.016\n",
      "Workstatus_5.0      0.0859      0.024      3.652      0.000       0.040       0.132\n",
      "Workstatus_6.0     -0.0920      0.018     -5.195      0.000      -0.127      -0.057\n",
      "Workstatus_7.0     -0.1544      0.036     -4.337      0.000      -0.224      -0.085\n",
      "Workstatus_8.0      0.0249      0.011      2.312      0.021       0.004       0.046\n",
      "Workstatus_9.0     -0.0013      0.012     -0.111      0.911      -0.025       0.022\n",
      "Workstatus_10.0    -0.0801      0.020     -4.010      0.000      -0.119      -0.041\n",
      "BMI_2.0             0.0130      0.048      0.270      0.787      -0.081       0.107\n",
      "BMI_3.0            -0.0468      0.046     -1.027      0.304      -0.136       0.042\n",
      "BMI_4.0            -0.0612      0.037     -1.669      0.095      -0.133       0.011\n",
      "BMI_5.0            -0.0651      0.026     -2.492      0.013      -0.116      -0.014\n",
      "IMD                -0.2024      0.015    -13.672      0.000      -0.231      -0.173\n",
      "Age                -0.4982      0.020    -24.952      0.000      -0.537      -0.459\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for -0.2425202517656979:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               179747\n",
      "Model:                          Logit   Df Residuals:                   179714\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04068\n",
      "Time:                        06:08:46   Log-Likelihood:                -18222.\n",
      "converged:                       True   LL-Null:                       -18994.\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.751e-305\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.0078      0.020   -198.062      0.000      -4.047      -3.968\n",
      "Child_2.0           0.0377      0.016      2.428      0.015       0.007       0.068\n",
      "Child_3.0           0.0442      0.015      2.901      0.004       0.014       0.074\n",
      "Child_4.0          -0.0314      0.016     -1.902      0.057      -0.064       0.001\n",
      "Diability_2.0       0.3316      0.028     11.901      0.000       0.277       0.386\n",
      "Education_2.0      -0.0675      0.017     -4.034      0.000      -0.100      -0.035\n",
      "Education_3.0      -0.0690      0.017     -3.960      0.000      -0.103      -0.035\n",
      "Education_4.0      -0.0312      0.019     -1.679      0.093      -0.068       0.005\n",
      "Education_5.0      -0.0410      0.018     -2.222      0.026      -0.077      -0.005\n",
      "Education_6.0      -0.1859      0.025     -7.392      0.000      -0.235      -0.137\n",
      "Ethnicity_2.0      -0.0336      0.017     -2.030      0.042      -0.066      -0.001\n",
      "Ethnicity_3.0       0.1401      0.012     11.392      0.000       0.116       0.164\n",
      "Ethnicity_4.0      -0.0673      0.022     -3.052      0.002      -0.111      -0.024\n",
      "Ethnicity_5.0       0.0828      0.009      8.852      0.000       0.064       0.101\n",
      "Ethnicity_6.0       0.0145      0.015      0.986      0.324      -0.014       0.043\n",
      "Ethnicity_7.0      -0.0127      0.018     -0.720      0.472      -0.047       0.022\n",
      "Gender_2.0         -0.1770      0.017    -10.294      0.000      -0.211      -0.143\n",
      "Gender_3.0          0.0197      0.019      1.010      0.312      -0.018       0.058\n",
      "Workstatus_2.0     -0.0229      0.018     -1.266      0.206      -0.058       0.013\n",
      "Workstatus_3.0     -0.0358      0.019     -1.850      0.064      -0.074       0.002\n",
      "Workstatus_4.0     -0.0766      0.026     -2.900      0.004      -0.128      -0.025\n",
      "Workstatus_5.0     -0.0327      0.026     -1.255      0.209      -0.084       0.018\n",
      "Workstatus_6.0     -0.0388      0.018     -2.134      0.033      -0.074      -0.003\n",
      "Workstatus_7.0     -0.1460      0.041     -3.553      0.000      -0.227      -0.065\n",
      "Workstatus_8.0      0.0999      0.013      7.705      0.000       0.075       0.125\n",
      "Workstatus_9.0      0.0104      0.014      0.758      0.448      -0.017       0.037\n",
      "Workstatus_10.0    -0.0181      0.019     -0.974      0.330      -0.055       0.018\n",
      "BMI_2.0            -0.0654      0.054     -1.222      0.222      -0.170       0.039\n",
      "BMI_3.0            -0.0648      0.050     -1.286      0.198      -0.164       0.034\n",
      "BMI_4.0            -0.1630      0.041     -3.937      0.000      -0.244      -0.082\n",
      "BMI_5.0            -0.1104      0.033     -3.389      0.001      -0.174      -0.047\n",
      "IMD                -0.1734      0.017    -10.266      0.000      -0.206      -0.140\n",
      "Age                -0.2015      0.026     -7.655      0.000      -0.253      -0.150\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for 0.3394674334341126:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               181535\n",
      "Model:                          Logit   Df Residuals:                   181502\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.03708\n",
      "Time:                        06:08:46   Log-Likelihood:                -18097.\n",
      "converged:                       True   LL-Null:                       -18794.\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.536e-273\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.0049      0.020   -205.162      0.000      -4.043      -3.967\n",
      "Child_2.0           0.0266      0.016      1.672      0.095      -0.005       0.058\n",
      "Child_3.0           0.0320      0.016      2.055      0.040       0.001       0.063\n",
      "Child_4.0           0.0053      0.016      0.340      0.734      -0.025       0.036\n",
      "Diability_2.0       0.2395      0.024      9.926      0.000       0.192       0.287\n",
      "Education_2.0      -0.0957      0.017     -5.580      0.000      -0.129      -0.062\n",
      "Education_3.0      -0.1075      0.018     -5.969      0.000      -0.143      -0.072\n",
      "Education_4.0      -0.0721      0.021     -3.454      0.001      -0.113      -0.031\n",
      "Education_5.0      -0.0911      0.020     -4.470      0.000      -0.131      -0.051\n",
      "Education_6.0      -0.1561      0.024     -6.584      0.000      -0.203      -0.110\n",
      "Ethnicity_2.0      -0.0625      0.018     -3.466      0.001      -0.098      -0.027\n",
      "Ethnicity_3.0       0.1531      0.012     12.828      0.000       0.130       0.177\n",
      "Ethnicity_4.0      -0.0744      0.023     -3.211      0.001      -0.120      -0.029\n",
      "Ethnicity_5.0       0.0739      0.010      7.663      0.000       0.055       0.093\n",
      "Ethnicity_6.0       0.0162      0.014      1.124      0.261      -0.012       0.044\n",
      "Ethnicity_7.0       0.0126      0.015      0.817      0.414      -0.018       0.043\n",
      "Gender_2.0         -0.1690      0.017     -9.828      0.000      -0.203      -0.135\n",
      "Gender_3.0         -0.0155      0.014     -1.072      0.284      -0.044       0.013\n",
      "Workstatus_2.0     -0.0205      0.018     -1.125      0.261      -0.056       0.015\n",
      "Workstatus_3.0     -0.0129      0.018     -0.738      0.460      -0.047       0.021\n",
      "Workstatus_4.0     -0.0798      0.026     -3.021      0.003      -0.132      -0.028\n",
      "Workstatus_5.0      0.0375      0.026      1.464      0.143      -0.013       0.088\n",
      "Workstatus_6.0     -0.0897      0.021     -4.195      0.000      -0.132      -0.048\n",
      "Workstatus_7.0     -0.1400      0.039     -3.631      0.000      -0.216      -0.064\n",
      "Workstatus_8.0      0.0830      0.014      6.143      0.000       0.057       0.109\n",
      "Workstatus_9.0      0.0034      0.015      0.233      0.816      -0.025       0.032\n",
      "Workstatus_10.0    -0.0221      0.019     -1.159      0.246      -0.059       0.015\n",
      "BMI_2.0             0.0132      0.059      0.226      0.822      -0.102       0.128\n",
      "BMI_3.0             0.0073      0.055      0.132      0.895      -0.101       0.115\n",
      "BMI_4.0            -0.1039      0.044     -2.343      0.019      -0.191      -0.017\n",
      "BMI_5.0            -0.0858      0.030     -2.819      0.005      -0.145      -0.026\n",
      "IMD                -0.1937      0.017    -11.361      0.000      -0.227      -0.160\n",
      "Age                -0.2244      0.026     -8.623      0.000      -0.275      -0.173\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for 0.9214551186339232:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               177735\n",
      "Model:                          Logit   Df Residuals:                   177702\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04956\n",
      "Time:                        06:08:46   Log-Likelihood:                -12455.\n",
      "converged:                       True   LL-Null:                       -13104.\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.081e-252\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.5916      0.028   -161.284      0.000      -4.647      -4.536\n",
      "Child_2.0           0.1243      0.018      6.756      0.000       0.088       0.160\n",
      "Child_3.0           0.1666      0.018      9.469      0.000       0.132       0.201\n",
      "Child_4.0           0.0674      0.018      3.774      0.000       0.032       0.102\n",
      "Diability_2.0       0.2903      0.032      8.944      0.000       0.227       0.354\n",
      "Education_2.0      -0.1781      0.025     -7.096      0.000      -0.227      -0.129\n",
      "Education_3.0      -0.1606      0.027     -6.024      0.000      -0.213      -0.108\n",
      "Education_4.0      -0.1071      0.043     -2.511      0.012      -0.191      -0.023\n",
      "Education_5.0      -0.0644      0.031     -2.093      0.036      -0.125      -0.004\n",
      "Education_6.0      -0.1346      0.040     -3.367      0.001      -0.213      -0.056\n",
      "Ethnicity_2.0      -0.0454      0.021     -2.166      0.030      -0.087      -0.004\n",
      "Ethnicity_3.0       0.1383      0.014     10.101      0.000       0.111       0.165\n",
      "Ethnicity_4.0      -0.0599      0.025     -2.435      0.015      -0.108      -0.012\n",
      "Ethnicity_5.0       0.0469      0.013      3.625      0.000       0.022       0.072\n",
      "Ethnicity_6.0       0.0066      0.017      0.377      0.706      -0.028       0.041\n",
      "Ethnicity_7.0      -0.0054      0.019     -0.285      0.776      -0.042       0.032\n",
      "Gender_2.0         -0.0778      0.022     -3.606      0.000      -0.120      -0.035\n",
      "Gender_3.0         -0.0451      0.027     -1.681      0.093      -0.098       0.007\n",
      "Workstatus_2.0      0.0104      0.022      0.470      0.638      -0.033       0.054\n",
      "Workstatus_3.0     -0.0277      0.019     -1.425      0.154      -0.066       0.010\n",
      "Workstatus_4.0     -0.0711      0.031     -2.278      0.023      -0.132      -0.010\n",
      "Workstatus_5.0     -0.0402      0.035     -1.149      0.251      -0.109       0.028\n",
      "Workstatus_6.0     -0.0468      0.022     -2.093      0.036      -0.091      -0.003\n",
      "Workstatus_7.0     -0.1018      0.044     -2.296      0.022      -0.189      -0.015\n",
      "Workstatus_8.0      0.1410      0.015      9.604      0.000       0.112       0.170\n",
      "Workstatus_9.0      0.0207      0.015      1.405      0.160      -0.008       0.050\n",
      "Workstatus_10.0    -0.0082      0.021     -0.383      0.702      -0.050       0.034\n",
      "BMI_2.0            -0.1664      0.058     -2.856      0.004      -0.281      -0.052\n",
      "BMI_3.0            -0.1798      0.056     -3.236      0.001      -0.289      -0.071\n",
      "BMI_4.0            -0.1965      0.046     -4.312      0.000      -0.286      -0.107\n",
      "BMI_5.0            -0.1275      0.036     -3.565      0.000      -0.198      -0.057\n",
      "IMD                -0.2142      0.021    -10.139      0.000      -0.256      -0.173\n",
      "Age                -0.2668      0.032     -8.258      0.000      -0.330      -0.203\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for 1.5034428038337337:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               177273\n",
      "Model:                          Logit   Df Residuals:                   177240\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05213\n",
      "Time:                        06:08:46   Log-Likelihood:                -8662.7\n",
      "converged:                       True   LL-Null:                       -9139.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.463e-179\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -5.0036      0.033   -152.138      0.000      -5.068      -4.939\n",
      "Child_2.0           0.0873      0.023      3.749      0.000       0.042       0.133\n",
      "Child_3.0           0.1243      0.022      5.632      0.000       0.081       0.168\n",
      "Child_4.0           0.0436      0.023      1.878      0.060      -0.002       0.089\n",
      "Diability_2.0       0.1898      0.036      5.272      0.000       0.119       0.260\n",
      "Education_2.0      -0.0786      0.026     -3.040      0.002      -0.129      -0.028\n",
      "Education_3.0      -0.0964      0.028     -3.413      0.001      -0.152      -0.041\n",
      "Education_4.0      -0.0561      0.034     -1.671      0.095      -0.122       0.010\n",
      "Education_5.0      -0.0635      0.033     -1.955      0.051      -0.127       0.000\n",
      "Education_6.0      -0.1405      0.038     -3.693      0.000      -0.215      -0.066\n",
      "Ethnicity_2.0       0.0137      0.023      0.583      0.560      -0.032       0.060\n",
      "Ethnicity_3.0       0.1808      0.016     11.351      0.000       0.150       0.212\n",
      "Ethnicity_4.0      -0.0897      0.035     -2.540      0.011      -0.159      -0.020\n",
      "Ethnicity_5.0       0.0960      0.011      8.502      0.000       0.074       0.118\n",
      "Ethnicity_6.0       0.0189      0.020      0.924      0.356      -0.021       0.059\n",
      "Ethnicity_7.0      -0.0106      0.025     -0.418      0.676      -0.060       0.039\n",
      "Gender_2.0         -0.2066      0.027     -7.740      0.000      -0.259      -0.154\n",
      "Gender_3.0         -0.0343      0.022     -1.562      0.118      -0.077       0.009\n",
      "Workstatus_2.0     -0.0256      0.029     -0.885      0.376      -0.082       0.031\n",
      "Workstatus_3.0     -0.0230      0.024     -0.946      0.344      -0.071       0.025\n",
      "Workstatus_4.0     -0.0101      0.027     -0.380      0.704      -0.063       0.042\n",
      "Workstatus_5.0     -0.0469      0.043     -1.086      0.278      -0.131       0.038\n",
      "Workstatus_6.0     -0.0444      0.029     -1.505      0.132      -0.102       0.013\n",
      "Workstatus_7.0     -0.1481      0.060     -2.469      0.014      -0.266      -0.031\n",
      "Workstatus_8.0      0.1260      0.019      6.774      0.000       0.090       0.162\n",
      "Workstatus_9.0      0.0363      0.016      2.257      0.024       0.005       0.068\n",
      "Workstatus_10.0    -0.0548      0.032     -1.704      0.088      -0.118       0.008\n",
      "BMI_2.0             0.0061      0.086      0.072      0.943      -0.162       0.174\n",
      "BMI_3.0          2.648e-05      0.081      0.000      1.000      -0.158       0.158\n",
      "BMI_4.0            -0.1955      0.067     -2.925      0.003      -0.326      -0.065\n",
      "BMI_5.0            -0.0258      0.036     -0.707      0.479      -0.097       0.046\n",
      "IMD                 0.2502      0.028      8.930      0.000       0.195       0.305\n",
      "Age                -0.2479      0.041     -6.095      0.000      -0.328      -0.168\n",
      "===================================================================================\n",
      "\n",
      "Regression Model for Combined:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:              1117755\n",
      "Model:                          Logit   Df Residuals:                  1117722\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04540\n",
      "Time:                        06:08:48   Log-Likelihood:            -1.0552e+05\n",
      "converged:                       True   LL-Null:                   -1.1054e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.1159      0.008   -489.109      0.000      -4.132      -4.099\n",
      "Child_2.0           0.0152      0.006      2.335      0.020       0.002       0.028\n",
      "Child_3.0           0.0411      0.006      6.556      0.000       0.029       0.053\n",
      "Child_4.0           0.0032      0.006      0.497      0.619      -0.009       0.016\n",
      "Diability_2.0       0.2784      0.011     25.523      0.000       0.257       0.300\n",
      "Education_2.0      -0.0992      0.007    -13.825      0.000      -0.113      -0.085\n",
      "Education_3.0      -0.0848      0.007    -11.306      0.000      -0.099      -0.070\n",
      "Education_4.0      -0.0596      0.009     -6.777      0.000      -0.077      -0.042\n",
      "Education_5.0      -0.0608      0.008     -7.154      0.000      -0.077      -0.044\n",
      "Education_6.0      -0.1575      0.010    -15.019      0.000      -0.178      -0.137\n",
      "Ethnicity_2.0      -0.0724      0.007     -9.818      0.000      -0.087      -0.058\n",
      "Ethnicity_3.0       0.1300      0.005     26.963      0.000       0.121       0.139\n",
      "Ethnicity_4.0      -0.0604      0.008     -7.254      0.000      -0.077      -0.044\n",
      "Ethnicity_5.0       0.0667      0.004     17.019      0.000       0.059       0.074\n",
      "Ethnicity_6.0       0.0040      0.006      0.673      0.501      -0.008       0.016\n",
      "Ethnicity_7.0      -0.0058      0.007     -0.871      0.384      -0.019       0.007\n",
      "Gender_2.0         -0.1543      0.007    -21.650      0.000      -0.168      -0.140\n",
      "Gender_3.0         -0.0344      0.010     -3.621      0.000      -0.053      -0.016\n",
      "Workstatus_2.0     -0.0212      0.008     -2.770      0.006      -0.036      -0.006\n",
      "Workstatus_3.0     -0.0412      0.007     -5.615      0.000      -0.056      -0.027\n",
      "Workstatus_4.0     -0.0773      0.010     -7.682      0.000      -0.097      -0.058\n",
      "Workstatus_5.0      0.0371      0.011      3.311      0.001       0.015       0.059\n",
      "Workstatus_6.0     -0.0679      0.008     -8.424      0.000      -0.084      -0.052\n",
      "Workstatus_7.0     -0.1358      0.016     -8.639      0.000      -0.167      -0.105\n",
      "Workstatus_8.0      0.0679      0.005     13.194      0.000       0.058       0.078\n",
      "Workstatus_9.0      0.0029      0.006      0.518      0.605      -0.008       0.014\n",
      "Workstatus_10.0    -0.0389      0.008     -4.755      0.000      -0.055      -0.023\n",
      "BMI_2.0            -0.0127      0.023     -0.560      0.575      -0.057       0.032\n",
      "BMI_3.0            -0.0457      0.021     -2.137      0.033      -0.088      -0.004\n",
      "BMI_4.0            -0.1297      0.017     -7.453      0.000      -0.164      -0.096\n",
      "BMI_5.0            -0.0848      0.012     -6.967      0.000      -0.109      -0.061\n",
      "IMD                -0.1817      0.007    -26.307      0.000      -0.195      -0.168\n",
      "Age                -0.3718      0.010    -36.179      0.000      -0.392      -0.352\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "time_col = X_scaled['Time']\n",
    "feature_col = X_scaled.drop(['Time'], axis=1)\n",
    "target_col = df_imputed['Plays_badminton']\n",
    "\n",
    "# Get the unique times\n",
    "unique_times = time_col.unique()\n",
    "\n",
    "# DataFrame to hold results\n",
    "results = []\n",
    "\n",
    "# Time-based regression\n",
    "for time in unique_times:\n",
    "    time_indices = time_col[time_col == time].index\n",
    "\n",
    "    X_time = feature_col.loc[time_indices]\n",
    "    y_time = target_col.loc[time_indices]\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = len(y_time) / (2 * np.bincount(y_time))\n",
    "\n",
    "    model = sm.Logit(y_time, sm.add_constant(X_time))\n",
    "    results_time = model.fit(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "\n",
    "    # Store the results in a list\n",
    "    results.append((time, results_time))\n",
    "\n",
    "# Combined times regression\n",
    "X = feature_col\n",
    "y = target_col\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights_combined = len(y) / (2 * np.bincount(y))\n",
    "\n",
    "model = sm.Logit(y, sm.add_constant(X))\n",
    "results_combined = model.fit(class_weight={0: class_weights_combined[0], 1: class_weights_combined[1]})\n",
    "\n",
    "# Store the results for the combined model\n",
    "results.append((\"Combined\", results_combined))\n",
    "\n",
    "# Print results\n",
    "for time, result in results:\n",
    "    print(f\"\\nRegression Model for {time}:\\n\")\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.118551\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.115013\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.101429\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.099195\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.070238\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049552\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:17: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol. The list of unsupported keyword arguments passed include: class_weight. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.094284\n",
      "         Iterations 9\n",
      "\n",
      "Regression Model for -1.4064956221653189:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               161263\n",
      "Model:                          Logit   Df Residuals:                   161231\n",
      "Method:                           MLE   Df Model:                           31\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05757\n",
      "Time:                        06:08:53   Log-Likelihood:                -19118.\n",
      "converged:                       True   LL-Null:                       -20286.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Child_2.0          -0.0047      0.015     -0.316      0.752      -0.034       0.025\n",
      "Child_3.0           0.0394      0.014      2.762      0.006       0.011       0.067\n",
      "Child_4.0           0.0010      0.015      0.068      0.946      -0.028       0.030\n",
      "Diability_2.0       0.2473      0.026      9.517      0.000       0.196       0.298\n",
      "Education_2.0      -0.0821      0.016     -5.146      0.000      -0.113      -0.051\n",
      "Education_3.0      -0.0852      0.017     -5.037      0.000      -0.118      -0.052\n",
      "Education_4.0      -0.0624      0.019     -3.303      0.001      -0.099      -0.025\n",
      "Education_5.0      -0.0610      0.019     -3.233      0.001      -0.098      -0.024\n",
      "Education_6.0      -0.1879      0.024     -7.713      0.000      -0.236      -0.140\n",
      "Ethnicity_2.0      -0.1008      0.018     -5.537      0.000      -0.136      -0.065\n",
      "Ethnicity_3.0       0.1398      0.011     12.564      0.000       0.118       0.162\n",
      "Ethnicity_4.0      -0.0506      0.018     -2.737      0.006      -0.087      -0.014\n",
      "Ethnicity_5.0       0.0735      0.009      8.210      0.000       0.056       0.091\n",
      "Ethnicity_6.0       0.0037      0.014      0.264      0.792      -0.024       0.031\n",
      "Ethnicity_7.0       0.0026      0.015      0.177      0.859      -0.026       0.031\n",
      "Gender_2.0         -0.1520      0.016     -9.351      0.000      -0.184      -0.120\n",
      "Gender_3.0        101.8510      0.520    195.991      0.000     100.832     102.869\n",
      "Workstatus_2.0     -0.0129      0.017     -0.738      0.461      -0.047       0.021\n",
      "Workstatus_3.0     -0.0341      0.017     -2.047      0.041      -0.067      -0.001\n",
      "Workstatus_4.0     -0.0937      0.025     -3.707      0.000      -0.143      -0.044\n",
      "Workstatus_5.0      0.0184      0.026      0.703      0.482      -0.033       0.070\n",
      "Workstatus_6.0     -0.0862      0.018     -4.709      0.000      -0.122      -0.050\n",
      "Workstatus_7.0     -0.0883      0.031     -2.878      0.004      -0.148      -0.028\n",
      "Workstatus_8.0      0.0675      0.011      6.004      0.000       0.045       0.090\n",
      "Workstatus_9.0     -0.0162      0.015     -1.101      0.271      -0.045       0.013\n",
      "Workstatus_10.0    -0.0276      0.018     -1.497      0.134      -0.064       0.009\n",
      "BMI_2.0             0.0406      0.052      0.775      0.438      -0.062       0.143\n",
      "BMI_3.0            -0.0116      0.050     -0.234      0.815      -0.109       0.086\n",
      "BMI_4.0            -0.0883      0.040     -2.184      0.029      -0.168      -0.009\n",
      "BMI_5.0            -0.0397      0.027     -1.488      0.137      -0.092       0.013\n",
      "IMD                -0.1960      0.016    -12.177      0.000      -0.228      -0.164\n",
      "Age                -0.4404      0.022    -19.636      0.000      -0.484      -0.396\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for -0.8245079369655084:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               159908\n",
      "Model:                          Logit   Df Residuals:                   159876\n",
      "Method:                           MLE   Df Model:                           31\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05592\n",
      "Time:                        06:08:53   Log-Likelihood:                -18391.\n",
      "converged:                       True   LL-Null:                       -19481.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Child_2.0          -0.0322      0.016     -2.057      0.040      -0.063      -0.002\n",
      "Child_3.0          -0.0203      0.015     -1.313      0.189      -0.051       0.010\n",
      "Child_4.0          -0.0044      0.015     -0.300      0.765      -0.033       0.024\n",
      "Diability_2.0       0.2760      0.026     10.478      0.000       0.224       0.328\n",
      "Education_2.0      -0.0991      0.017     -5.924      0.000      -0.132      -0.066\n",
      "Education_3.0      -0.0682      0.017     -3.929      0.000      -0.102      -0.034\n",
      "Education_4.0      -0.0883      0.021     -4.139      0.000      -0.130      -0.047\n",
      "Education_5.0      -0.0712      0.020     -3.594      0.000      -0.110      -0.032\n",
      "Education_6.0      -0.1634      0.025     -6.633      0.000      -0.212      -0.115\n",
      "Ethnicity_2.0      -0.0786      0.018     -4.452      0.000      -0.113      -0.044\n",
      "Ethnicity_3.0       0.1300      0.012     11.288      0.000       0.107       0.153\n",
      "Ethnicity_4.0      -0.0195      0.017     -1.158      0.247      -0.052       0.013\n",
      "Ethnicity_5.0       0.0638      0.010      6.653      0.000       0.045       0.083\n",
      "Ethnicity_6.0       0.0048      0.014      0.350      0.727      -0.022       0.032\n",
      "Ethnicity_7.0      -0.0073      0.017     -0.439      0.661      -0.040       0.025\n",
      "Gender_2.0         -0.1363      0.017     -8.254      0.000      -0.169      -0.104\n",
      "Gender_3.0        103.1252      0.535    192.687      0.000     102.076     104.174\n",
      "Workstatus_2.0     -0.0513      0.018     -2.781      0.005      -0.087      -0.015\n",
      "Workstatus_3.0     -0.0358      0.018     -2.023      0.043      -0.070      -0.001\n",
      "Workstatus_4.0     -0.0419      0.021     -1.998      0.046      -0.083      -0.001\n",
      "Workstatus_5.0      0.0845      0.026      3.210      0.001       0.033       0.136\n",
      "Workstatus_6.0     -0.0875      0.019     -4.538      0.000      -0.125      -0.050\n",
      "Workstatus_7.0     -0.1348      0.038     -3.581      0.000      -0.209      -0.061\n",
      "Workstatus_8.0      0.0241      0.012      2.007      0.045       0.001       0.048\n",
      "Workstatus_9.0     -0.0017      0.013     -0.128      0.898      -0.028       0.024\n",
      "Workstatus_10.0    -0.0704      0.022     -3.232      0.001      -0.113      -0.028\n",
      "BMI_2.0             0.0077      0.053      0.146      0.884      -0.096       0.112\n",
      "BMI_3.0            -0.0522      0.050     -1.034      0.301      -0.151       0.047\n",
      "BMI_4.0            -0.0677      0.041     -1.664      0.096      -0.148       0.012\n",
      "BMI_5.0            -0.0601      0.028     -2.121      0.034      -0.116      -0.005\n",
      "IMD                -0.2114      0.016    -12.816      0.000      -0.244      -0.179\n",
      "Age                -0.4988      0.022    -22.397      0.000      -0.542      -0.455\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for -0.2425202517656979:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               143797\n",
      "Model:                          Logit   Df Residuals:                   143764\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04002\n",
      "Time:                        06:08:54   Log-Likelihood:                -14585.\n",
      "converged:                       True   LL-Null:                       -15193.\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.130e-235\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.0076      0.023   -175.999      0.000      -4.052      -3.963\n",
      "Child_2.0           0.0241      0.018      1.378      0.168      -0.010       0.058\n",
      "Child_3.0           0.0434      0.017      2.552      0.011       0.010       0.077\n",
      "Child_4.0          -0.0319      0.018     -1.742      0.082      -0.068       0.004\n",
      "Diability_2.0       0.3269      0.031     10.541      0.000       0.266       0.388\n",
      "Education_2.0      -0.0651      0.019     -3.482      0.000      -0.102      -0.028\n",
      "Education_3.0      -0.0670      0.019     -3.440      0.001      -0.105      -0.029\n",
      "Education_4.0      -0.0224      0.020     -1.110      0.267      -0.062       0.017\n",
      "Education_5.0      -0.0445      0.021     -2.134      0.033      -0.085      -0.004\n",
      "Education_6.0      -0.1735      0.028     -6.274      0.000      -0.228      -0.119\n",
      "Ethnicity_2.0      -0.0272      0.018     -1.476      0.140      -0.063       0.009\n",
      "Ethnicity_3.0       0.1394      0.014     10.141      0.000       0.112       0.166\n",
      "Ethnicity_4.0      -0.0567      0.024     -2.392      0.017      -0.103      -0.010\n",
      "Ethnicity_5.0       0.0828      0.010      7.911      0.000       0.062       0.103\n",
      "Ethnicity_6.0       0.0056      0.017      0.328      0.743      -0.028       0.039\n",
      "Ethnicity_7.0      -0.0032      0.019     -0.169      0.866      -0.040       0.034\n",
      "Gender_2.0         -0.1737      0.019     -9.032      0.000      -0.211      -0.136\n",
      "Gender_3.0          0.0184      0.022      0.818      0.413      -0.026       0.062\n",
      "Workstatus_2.0     -0.0162      0.020     -0.803      0.422      -0.056       0.023\n",
      "Workstatus_3.0     -0.0272      0.021     -1.288      0.198      -0.069       0.014\n",
      "Workstatus_4.0     -0.0672      0.029     -2.351      0.019      -0.123      -0.011\n",
      "Workstatus_5.0     -0.0313      0.029     -1.076      0.282      -0.088       0.026\n",
      "Workstatus_6.0     -0.0329      0.020     -1.640      0.101      -0.072       0.006\n",
      "Workstatus_7.0     -0.1613      0.048     -3.370      0.001      -0.255      -0.067\n",
      "Workstatus_8.0      0.1001      0.015      6.896      0.000       0.072       0.129\n",
      "Workstatus_9.0      0.0086      0.015      0.562      0.574      -0.021       0.039\n",
      "Workstatus_10.0    -0.0199      0.021     -0.946      0.344      -0.061       0.021\n",
      "BMI_2.0            -0.0935      0.059     -1.592      0.111      -0.209       0.022\n",
      "BMI_3.0            -0.0845      0.055     -1.526      0.127      -0.193       0.024\n",
      "BMI_4.0            -0.1864      0.046     -4.077      0.000      -0.276      -0.097\n",
      "BMI_5.0            -0.1672      0.043     -3.857      0.000      -0.252      -0.082\n",
      "IMD                -0.1695      0.019     -8.977      0.000      -0.207      -0.133\n",
      "Age                -0.2037      0.029     -6.925      0.000      -0.261      -0.146\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for 0.3394674334341126:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               145228\n",
      "Model:                          Logit   Df Residuals:                   145195\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.03861\n",
      "Time:                        06:08:54   Log-Likelihood:                -14406.\n",
      "converged:                       True   LL-Null:                       -14984.\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.154e-222\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.0156      0.022   -183.306      0.000      -4.058      -3.973\n",
      "Child_2.0           0.0084      0.018      0.463      0.643      -0.027       0.044\n",
      "Child_3.0           0.0266      0.017      1.525      0.127      -0.008       0.061\n",
      "Child_4.0           0.0014      0.018      0.082      0.935      -0.033       0.036\n",
      "Diability_2.0       0.2355      0.027      8.730      0.000       0.183       0.288\n",
      "Education_2.0      -0.0954      0.019     -4.973      0.000      -0.133      -0.058\n",
      "Education_3.0      -0.1286      0.021     -6.233      0.000      -0.169      -0.088\n",
      "Education_4.0      -0.0755      0.024     -3.213      0.001      -0.122      -0.029\n",
      "Education_5.0      -0.0839      0.022     -3.744      0.000      -0.128      -0.040\n",
      "Education_6.0      -0.1747      0.027     -6.404      0.000      -0.228      -0.121\n",
      "Ethnicity_2.0      -0.0634      0.020     -3.124      0.002      -0.103      -0.024\n",
      "Ethnicity_3.0       0.1618      0.013     12.291      0.000       0.136       0.188\n",
      "Ethnicity_4.0      -0.0861      0.027     -3.144      0.002      -0.140      -0.032\n",
      "Ethnicity_5.0       0.0745      0.011      6.940      0.000       0.053       0.096\n",
      "Ethnicity_6.0       0.0114      0.016      0.692      0.489      -0.021       0.044\n",
      "Ethnicity_7.0       0.0193      0.017      1.144      0.253      -0.014       0.052\n",
      "Gender_2.0         -0.1817      0.019     -9.434      0.000      -0.219      -0.144\n",
      "Gender_3.0         -0.0182      0.017     -1.064      0.287      -0.052       0.015\n",
      "Workstatus_2.0     -0.0333      0.021     -1.610      0.107      -0.074       0.007\n",
      "Workstatus_3.0     -0.0039      0.019     -0.205      0.837      -0.041       0.033\n",
      "Workstatus_4.0     -0.0785      0.029     -2.675      0.007      -0.136      -0.021\n",
      "Workstatus_5.0      0.0432      0.029      1.507      0.132      -0.013       0.099\n",
      "Workstatus_6.0     -0.0996      0.025     -4.037      0.000      -0.148      -0.051\n",
      "Workstatus_7.0     -0.1234      0.041     -2.996      0.003      -0.204      -0.043\n",
      "Workstatus_8.0      0.0750      0.015      4.925      0.000       0.045       0.105\n",
      "Workstatus_9.0      0.0012      0.017      0.073      0.942      -0.032       0.034\n",
      "Workstatus_10.0    -0.0194      0.021     -0.919      0.358      -0.061       0.022\n",
      "BMI_2.0             0.0230      0.067      0.344      0.731      -0.108       0.154\n",
      "BMI_3.0             0.0200      0.062      0.320      0.749      -0.102       0.142\n",
      "BMI_4.0            -0.0868      0.050     -1.730      0.084      -0.185       0.012\n",
      "BMI_5.0            -0.0784      0.034     -2.305      0.021      -0.145      -0.012\n",
      "IMD                -0.1938      0.019    -10.138      0.000      -0.231      -0.156\n",
      "Age                -0.2389      0.029     -8.204      0.000      -0.296      -0.182\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for 0.9214551186339232:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               142188\n",
      "Model:                          Logit   Df Residuals:                   142155\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04973\n",
      "Time:                        06:08:54   Log-Likelihood:                -9987.0\n",
      "converged:                       True   LL-Null:                       -10510.\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.836e-199\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.5999      0.032   -142.428      0.000      -4.663      -4.537\n",
      "Child_2.0           0.1407      0.020      6.926      0.000       0.101       0.181\n",
      "Child_3.0           0.1649      0.020      8.354      0.000       0.126       0.204\n",
      "Child_4.0           0.0615      0.020      3.026      0.002       0.022       0.101\n",
      "Diability_2.0       0.2887      0.036      7.982      0.000       0.218       0.360\n",
      "Education_2.0      -0.1761      0.028     -6.243      0.000      -0.231      -0.121\n",
      "Education_3.0      -0.1622      0.030     -5.448      0.000      -0.221      -0.104\n",
      "Education_4.0      -0.1571      0.058     -2.727      0.006      -0.270      -0.044\n",
      "Education_5.0      -0.0839      0.036     -2.353      0.019      -0.154      -0.014\n",
      "Education_6.0      -0.1342      0.045     -2.997      0.003      -0.222      -0.046\n",
      "Ethnicity_2.0      -0.0553      0.024     -2.306      0.021      -0.102      -0.008\n",
      "Ethnicity_3.0       0.1403      0.015      9.184      0.000       0.110       0.170\n",
      "Ethnicity_4.0      -0.0609      0.028     -2.214      0.027      -0.115      -0.007\n",
      "Ethnicity_5.0       0.0431      0.015      2.838      0.005       0.013       0.073\n",
      "Ethnicity_6.0       0.0030      0.020      0.152      0.879      -0.036       0.042\n",
      "Ethnicity_7.0      -0.0028      0.021     -0.135      0.892      -0.044       0.038\n",
      "Gender_2.0         -0.0811      0.024     -3.370      0.001      -0.128      -0.034\n",
      "Gender_3.0         -0.0611      0.038     -1.615      0.106      -0.135       0.013\n",
      "Workstatus_2.0      0.0100      0.025      0.407      0.684      -0.038       0.058\n",
      "Workstatus_3.0     -0.0249      0.021     -1.157      0.247      -0.067       0.017\n",
      "Workstatus_4.0     -0.0601      0.034     -1.790      0.074      -0.126       0.006\n",
      "Workstatus_5.0     -0.0745      0.039     -1.912      0.056      -0.151       0.002\n",
      "Workstatus_6.0     -0.0410      0.025     -1.655      0.098      -0.089       0.008\n",
      "Workstatus_7.0     -0.0956      0.048     -1.980      0.048      -0.190      -0.001\n",
      "Workstatus_8.0      0.1441      0.017      8.709      0.000       0.112       0.177\n",
      "Workstatus_9.0      0.0319      0.015      2.069      0.039       0.002       0.062\n",
      "Workstatus_10.0    -0.0129      0.024     -0.539      0.590      -0.060       0.034\n",
      "BMI_2.0            -0.1754      0.064     -2.724      0.006      -0.302      -0.049\n",
      "BMI_3.0            -0.1974      0.062     -3.209      0.001      -0.318      -0.077\n",
      "BMI_4.0            -0.1828      0.050     -3.650      0.000      -0.281      -0.085\n",
      "BMI_5.0            -0.1880      0.049     -3.840      0.000      -0.284      -0.092\n",
      "IMD                -0.2248      0.024     -9.497      0.000      -0.271      -0.178\n",
      "Age                -0.2252      0.036     -6.261      0.000      -0.296      -0.155\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for 1.5034428038337337:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               141818\n",
      "Model:                          Logit   Df Residuals:                   141785\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.05257\n",
      "Time:                        06:08:54   Log-Likelihood:                -7027.3\n",
      "converged:                       True   LL-Null:                       -7417.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.673e-143\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.9906      0.037   -135.814      0.000      -5.063      -4.919\n",
      "Child_2.0           0.0876      0.026      3.390      0.001       0.037       0.138\n",
      "Child_3.0           0.1194      0.025      4.867      0.000       0.071       0.167\n",
      "Child_4.0           0.0540      0.025      2.160      0.031       0.005       0.103\n",
      "Diability_2.0       0.2052      0.041      5.043      0.000       0.125       0.285\n",
      "Education_2.0      -0.0794      0.029     -2.768      0.006      -0.136      -0.023\n",
      "Education_3.0      -0.1027      0.032     -3.253      0.001      -0.165      -0.041\n",
      "Education_4.0      -0.0528      0.037     -1.433      0.152      -0.125       0.019\n",
      "Education_5.0      -0.0661      0.036     -1.825      0.068      -0.137       0.005\n",
      "Education_6.0      -0.1159      0.041     -2.837      0.005      -0.196      -0.036\n",
      "Ethnicity_2.0       0.0217      0.026      0.848      0.397      -0.028       0.072\n",
      "Ethnicity_3.0       0.1845      0.018     10.515      0.000       0.150       0.219\n",
      "Ethnicity_4.0      -0.0985      0.041     -2.420      0.016      -0.178      -0.019\n",
      "Ethnicity_5.0       0.0913      0.013      7.081      0.000       0.066       0.117\n",
      "Ethnicity_6.0       0.0195      0.023      0.865      0.387      -0.025       0.064\n",
      "Ethnicity_7.0      -0.0180      0.029     -0.615      0.539      -0.075       0.039\n",
      "Gender_2.0         -0.2039      0.030     -6.891      0.000      -0.262      -0.146\n",
      "Gender_3.0         -0.0241      0.022     -1.095      0.274      -0.067       0.019\n",
      "Workstatus_2.0     -0.0094      0.032     -0.299      0.765      -0.071       0.052\n",
      "Workstatus_3.0     -0.0273      0.027     -0.997      0.319      -0.081       0.026\n",
      "Workstatus_4.0     -0.0262      0.032     -0.831      0.406      -0.088       0.036\n",
      "Workstatus_5.0     -0.0614      0.048     -1.281      0.200      -0.155       0.033\n",
      "Workstatus_6.0     -0.0579      0.033     -1.731      0.083      -0.123       0.008\n",
      "Workstatus_7.0     -0.1659      0.071     -2.343      0.019      -0.305      -0.027\n",
      "Workstatus_8.0      0.1219      0.021      5.894      0.000       0.081       0.162\n",
      "Workstatus_9.0      0.0354      0.018      1.992      0.046       0.001       0.070\n",
      "Workstatus_10.0    -0.0737      0.037     -1.977      0.048      -0.147      -0.001\n",
      "BMI_2.0             0.0022      0.095      0.023      0.981      -0.184       0.188\n",
      "BMI_3.0            -0.0358      0.090     -0.399      0.690      -0.211       0.140\n",
      "BMI_4.0            -0.2208      0.074     -2.965      0.003      -0.367      -0.075\n",
      "BMI_5.0            -0.0478      0.042     -1.127      0.260      -0.131       0.035\n",
      "IMD                 0.2421      0.031      7.806      0.000       0.181       0.303\n",
      "Age                -0.2349      0.045     -5.234      0.000      -0.323      -0.147\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Regression Model for Combined:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Plays_badminton   No. Observations:               894204\n",
      "Model:                          Logit   Df Residuals:                   894171\n",
      "Method:                           MLE   Df Model:                           32\n",
      "Date:                Sat, 15 Jul 2023   Pseudo R-squ.:                 0.04470\n",
      "Time:                        06:08:55   Log-Likelihood:                -84309.\n",
      "converged:                       True   LL-Null:                       -88254.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.1143      0.009   -438.410      0.000      -4.133      -4.096\n",
      "Child_2.0           0.0123      0.007      1.689      0.091      -0.002       0.027\n",
      "Child_3.0           0.0431      0.007      6.145      0.000       0.029       0.057\n",
      "Child_4.0           0.0047      0.007      0.663      0.507      -0.009       0.019\n",
      "Diability_2.0       0.2728      0.012     22.531      0.000       0.249       0.297\n",
      "Education_2.0      -0.0971      0.008    -12.112      0.000      -0.113      -0.081\n",
      "Education_3.0      -0.0837      0.008     -9.988      0.000      -0.100      -0.067\n",
      "Education_4.0      -0.0591      0.010     -6.010      0.000      -0.078      -0.040\n",
      "Education_5.0      -0.0665      0.010     -6.923      0.000      -0.085      -0.048\n",
      "Education_6.0      -0.1601      0.012    -13.617      0.000      -0.183      -0.137\n",
      "Ethnicity_2.0      -0.0677      0.008     -8.265      0.000      -0.084      -0.052\n",
      "Ethnicity_3.0       0.1276      0.005     23.491      0.000       0.117       0.138\n",
      "Ethnicity_4.0      -0.0555      0.009     -6.046      0.000      -0.073      -0.037\n",
      "Ethnicity_5.0       0.0658      0.004     14.789      0.000       0.057       0.075\n",
      "Ethnicity_6.0       0.0060      0.007      0.904      0.366      -0.007       0.019\n",
      "Ethnicity_7.0      -0.0035      0.007     -0.481      0.631      -0.018       0.011\n",
      "Gender_2.0         -0.1539      0.008    -19.298      0.000      -0.170      -0.138\n",
      "Gender_3.0         -0.0409      0.011     -3.573      0.000      -0.063      -0.018\n",
      "Workstatus_2.0     -0.0188      0.009     -2.196      0.028      -0.036      -0.002\n",
      "Workstatus_3.0     -0.0376      0.008     -4.632      0.000      -0.054      -0.022\n",
      "Workstatus_4.0     -0.0790      0.011     -6.961      0.000      -0.101      -0.057\n",
      "Workstatus_5.0      0.0442      0.013      3.534      0.000       0.020       0.069\n",
      "Workstatus_6.0     -0.0710      0.009     -7.795      0.000      -0.089      -0.053\n",
      "Workstatus_7.0     -0.1351      0.018     -7.714      0.000      -0.169      -0.101\n",
      "Workstatus_8.0      0.0680      0.006     11.799      0.000       0.057       0.079\n",
      "Workstatus_9.0      0.0052      0.006      0.848      0.397      -0.007       0.017\n",
      "Workstatus_10.0    -0.0369      0.009     -4.039      0.000      -0.055      -0.019\n",
      "BMI_2.0            -0.0359      0.025     -1.435      0.151      -0.085       0.013\n",
      "BMI_3.0            -0.0619      0.024     -2.618      0.009      -0.108      -0.016\n",
      "BMI_4.0            -0.1429      0.019     -7.419      0.000      -0.181      -0.105\n",
      "BMI_5.0            -0.0831      0.013     -6.280      0.000      -0.109      -0.057\n",
      "IMD                -0.1809      0.008    -23.399      0.000      -0.196      -0.166\n",
      "Age                -0.3744      0.011    -32.556      0.000      -0.397      -0.352\n",
      "===================================================================================\n",
      "Test Set Evaluation:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "time_col = X_scaled['Time']\n",
    "feature_col = X_scaled.drop(['Time'], axis=1)\n",
    "target_col = df_imputed['Plays_badminton']\n",
    "\n",
    "# Get the unique times\n",
    "unique_times = time_col.unique()\n",
    "\n",
    "# DataFrame to hold results\n",
    "results = []\n",
    "\n",
    "# Train-test split parameters\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "# Time-based regression\n",
    "for time in unique_times:\n",
    "    time_indices = time_col[time_col == time].index\n",
    "\n",
    "    X_time = feature_col.loc[time_indices]\n",
    "    y_time = target_col.loc[time_indices]\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = len(y_time) / (2 * np.bincount(y_time))\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_time, y_time, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "    results_time = model.fit(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "\n",
    "    # Store the results in a list\n",
    "    results.append((time, results_time, X_test, y_test))\n",
    "\n",
    "# Combined times regression\n",
    "X = feature_col\n",
    "y = target_col\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights_combined = len(y) / (2 * np.bincount(y))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "results_combined = model.fit(class_weight={0: class_weights_combined[0], 1: class_weights_combined[1]})\n",
    "\n",
    "# Store the results for the combined model\n",
    "results.append((\"Combined\", results_combined, X_test, y_test))\n",
    "\n",
    "# Print results\n",
    "for time, result, X_test, y_test in results:\n",
    "    print(f\"\\nRegression Model for {time}:\\n\")\n",
    "    print(result.summary())\n",
    "\n",
    "    # Additional evaluation on the test set\n",
    "    y_pred = result.predict(sm.add_constant(X_test))\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    precision = precision_score(y_test, y_pred_binary)\n",
    "    recall = recall_score(y_test, y_pred_binary)\n",
    "    f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "    print(\"Test Set Evaluation:\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
